services:
  # Qdrant Vector Database - LOCAL DEVELOPMENT ONLY
  # For production, use Qdrant Cloud (https://cloud.qdrant.io/)
  # This is optional for local testing before uploading to cloud
  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: doctor-ai-qdrant
    pull_policy: missing
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:6333/"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    networks:
      - doctor-ai-network
    profiles:
      - local-dev

  # PostgreSQL Database - LOCAL DEVELOPMENT ONLY (OPTIONAL)
  # For production on Vercel, use Vercel Postgres instead
  postgres:
    image: postgres:15-alpine
    container_name: doctor-ai-postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-doctor_ai}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme_secure_password}
      POSTGRES_DB: ${POSTGRES_DB:-doctor_ai}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U doctor_ai -d doctor_ai"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    networks:
      - doctor-ai-network
    profiles:
      - local-dev

  # Redis Cache - LOCAL DEVELOPMENT ONLY (OPTIONAL)
  redis:
    image: redis:7-alpine
    container_name: doctor-ai-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    networks:
      - doctor-ai-network
    profiles:
      - local-dev

  # FastAPI Application - LOCAL DEVELOPMENT ONLY
  # For production, deploy to Vercel as serverless functions
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: doctor-ai-api
    ports:
      - "8000:8000"
    environment:
      PRIMARY_DATABASE: qdrant
      QDRANT_HOST: qdrant
      QDRANT_PORT: 6333
      DATABASE_URL: postgresql://${POSTGRES_USER:-doctor_ai}:${POSTGRES_PASSWORD:-changeme_secure_password}@postgres:5432/${POSTGRES_DB:-doctor_ai}
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_ENABLED: ${REDIS_ENABLED:-true}
      SECRET_KEY: ${SECRET_KEY}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
    env_file:
      - .env
    depends_on:
      qdrant:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - doctor-ai-network
    profiles:
      - local-dev

networks:
  doctor-ai-network:
    driver: bridge

volumes:
  qdrant_storage:
  postgres_data:
  redis_data:
